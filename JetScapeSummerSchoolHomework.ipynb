{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prediction maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model setup is as follows: we have dijet asymmetry data prepared, where the asymmetry AJ is defined as the difference between the two jets divided by the sum. Specifically,\n",
    "\n",
    "$$A_{\\mathrm{j}} = \\frac{p_{\\mathrm{T, 1}} - p_{\\mathrm{T, 2}}}{p_{\\mathrm{T, 1}} + p_{\\mathrm{T, 2}}}$$\n",
    "\n",
    "We will construct a model to describe the energy loss observed in the dijet asymmetry.  For this model, we consider back-to-back dijets.  Each jet can lose energy, and the lost energy is parameterized as\n",
    "\n",
    "$$ \\Delta p_{\\mathrm{T}} / p_{\\mathrm{T}} \\sim Gaus(A, B)$$\n",
    "\n",
    "In addition to the energy loss contribution, we have extra \"apparent\" smearing on the AJ coming from the fact that we have other processes going on in the events (three jets etc).  It is parameterized as a Gaussian smearing on AJ with width C. So there are three total parameters: A, B, and C.\n",
    "\n",
    "The measurement is done in two bins of centrality.  One in central event, where (A, B, C) are all relevant, and another one in very peripheral event, where only the parameter (C) is relevant.\n",
    "\n",
    "The goal here in this notebook is to make the inputs needed for Bayesian inference to learn about A, B and C from the provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "Folder = 'input/AJHomework/'\n",
    "\n",
    "if not os.path.exists(Folder):\n",
    "    os.mkdir(Folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataXMin        = 0.000\n",
    "DataXMax        = 1.000\n",
    "DataXBin        = 0.025\n",
    "\n",
    "DataNBin        = int((DataXMax - DataXMin) / DataXBin)\n",
    "\n",
    "# how many design points do you want to generate?\n",
    "NDesign         = ______\n",
    "\n",
    "# What is the upper parameter range (one each for A, B, C)?\n",
    "# The lower range for each parameter is 0 by construction.\n",
    "# Hint: start with a large-range guess!  Then we can come back and reduce range\n",
    "ParameterRanges = [______]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"prediction\" function\n",
    "\n",
    "Let's write a function, where we do the required smearing, make a histogram on the final AJ, and return the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(A, B, C):\n",
    "    N = 100000\n",
    "    \n",
    "    Hist = np.zeros(DataNBin)\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Jet 1 and jet 2 PT (J1 and J2) after quenching.\n",
    "        # Assuming initial energy is 100 GeV, and (delta PT / PT) ~ gaus(A, B), calculate the final energy\n",
    "        # Jet PT = 100 GeV * (?)\n",
    "        # Note that the initial energy cancels out in AJ\n",
    "        # Useful function: np.random.normal(1, 2) gives you a random sampling with gaussian mean 1 and sigma 2\n",
    "        J1 = ______\n",
    "        J2 = ______\n",
    "        # Calculate AJ from the PTs\n",
    "        AJ = (J1 - J2) / (J1 + J2)\n",
    "        # Adding extra gaussian smearing from parameter C\n",
    "        AJ = AJ + ______\n",
    "        # AJ is defined to be leading - subleading -> positive!\n",
    "        AJ = np.abs(AJ)\n",
    "\n",
    "        # put things into bins\n",
    "        Bin = int((AJ - DataXMin) / DataXBin)\n",
    "        if Bin < 0:   # underflow\n",
    "            Bin = 0\n",
    "        if Bin >= DataNBin:   # overflow\n",
    "            Bin = DataNBin - 1\n",
    "        \n",
    "        Hist[Bin] = Hist[Bin] + 1\n",
    "        \n",
    "    return Hist / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the prediction (cross check for yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predicting one point - to see if the output makes sense or not\n",
    "# Once you are happy, we move on!\n",
    "example_prediction = Predict(______, ______, ______)\n",
    "example_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively (or in addition), plot the AJ distribution for our single point\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.plot(np.arange(DataXMin, DataXMax, DataXBin) + (DataXBin / 2), example_prediction, marker=\"o\", linestyle=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the design points\n",
    "\n",
    "Let's start with a very simple random array :D\n",
    "\n",
    "In reality we would use something more complicated to distribute the points better, but let's start simple.  Fancy stuff is just a better way to achieve the same purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Design = np.random.rand(NDesign, 3) * ParameterRanges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the model predictions\n",
    "\n",
    "Let's loop over the design points, and call the predict function we just wrote to make a big table!\n",
    "\n",
    "This step takes a while, like a few minutes.  Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction for \"central\" data\n",
    "Y1 = [Predict(______, ______, ______) for i in Design]\n",
    "# Generate prediction for \"peripheral\" data.  Note here A and B are irrelevant.  So we set them to 0\n",
    "Y2 = [Predict(______, ______, ______) for i in Design]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write everything out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Folder + 'Prediction_Selection1.dat', 'w') as f:\n",
    "    f.write('# Version 1.0\\n')\n",
    "    f.write('# Data Data_Selection1.dat\\n')\n",
    "    f.write('# Design Design.dat\\n')\n",
    "    np.savetxt(f, np.transpose(Y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Folder + 'Prediction_Selection2.dat', 'w') as f:\n",
    "    f.write('# Version 1.0\\n')\n",
    "    f.write('# Data Data_Selection2.dat\\n')\n",
    "    f.write('# Design Design.dat\\n')\n",
    "    np.savetxt(f, np.transpose(Y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Folder + 'Design.dat', 'w') as f:\n",
    "    f.write('# Version 1.0\\n')\n",
    "    f.write('# Parameter A B C\\n')\n",
    "    np.savetxt(f, Design)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
