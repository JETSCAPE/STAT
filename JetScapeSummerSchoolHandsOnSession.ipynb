{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple exercise on Bayesian analysis\n",
    "\n",
    "For the first hands on exercise, we will perform a simple Bayesian analysis example with only one dataset.\n",
    "\n",
    "**These exercises are interactive**: a number of cells include `_______`, which signal that you should fill in the required value. If you've unable to execute a cell, carefully check whether you've filled in all of the required values.\n",
    "\n",
    "## Step 0: load all relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process import kernels\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from scipy.linalg import lapack\n",
    "from scipy import stats\n",
    "import emcee\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import src.reader as Reader\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: prepare input files\n",
    "\n",
    "We need to perform some setup to load and format the data properly for the Bayesian analysis framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load measured data, design points, and prediction from text files\n",
    "\n",
    "Check the available files in the `input/SimpleExample` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data files\n",
    "RawData1       = Reader.ReadData('input/SimpleExample/______')\n",
    "\n",
    "# Read design points\n",
    "RawDesign      = Reader.ReadDesign('input/SimpleExample/______')\n",
    "\n",
    "# Read model prediction\n",
    "# Each prediction corresponds to a design point\n",
    "RawPrediction1 = Reader.ReadPrediction('input/SimpleExample/______')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this block to prepare the inputs\n",
    "\n",
    "Now we combine the input data into a dictionary formatted according to the input expected by the framework. `AllData` will conatain all data, design points, predictions, and covariance between the data points. It also conatins general information about the input information (parameters, ranges, etc).\n",
    "\n",
    "For our example, we are measuring some observable `Y`. We label each measurement of an observable as `C{N}` (for example, `C0` for the first measurement) (where `C` is a \"column name\" in data).\n",
    "\n",
    "Once we've fully constructed the input information, it will be stored onto the filesystem. Later steps will access this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionary\n",
    "AllData = {}\n",
    "\n",
    "# Basic information\n",
    "AllData[\"systems\"] = [\"PbPb5020\"]\n",
    "AllData[\"keys\"] = RawDesign[\"Parameter\"]\n",
    "AllData[\"labels\"] = RawDesign[\"Parameter\"]\n",
    "AllData[\"ranges\"] = [(0, 1), (0, 1), (0, 1)]\n",
    "AllData[\"observables\"] = [('Y', ['C0'])]\n",
    "\n",
    "# Data points\n",
    "Data = {\"PbPb5020\": {\"Y\": {\"C0\": RawData1[\"Data\"]}}}\n",
    "\n",
    "# Model predictions\n",
    "Prediction = {\"PbPb5020\": {\"Y\": {\"C0\": {\"Y\": RawPrediction1[\"Prediction\"], \"x\": RawData1[\"Data\"]['x']}}}}\n",
    "\n",
    "# Covariance matrices - the indices are [system][measurement1][measurement2], each one is a block of matrix\n",
    "Covariance = Reader.InitializeCovariance(Data)\n",
    "Covariance[\"PbPb5020\"][(\"Y\", \"C0\")][(\"Y\", \"C0\")] = Reader.EstimateCovariance(RawData1, RawData1, SysLength = {\"default\": 0.2})\n",
    "\n",
    "# This is how we can add off-diagonal matrices\n",
    "# Covariance[\"PbPb5020\"][(\"R_AA\", \"C0\")][(\"R_AA\", \"C1\")] = Reader.EstimateCovariance(RawData1, RawData2, SysLength = {\"default\": 100}, SysStrength = {\"default\": 0.1})\n",
    "# Covariance[\"PbPb5020\"][(\"R_AA\", \"C1\")][(\"R_AA\", \"C0\")] = Reader.EstimateCovariance(RawData2, RawData1, SysLength = {\"default\": 100}, SysStrength = {\"default\": 0.1})\n",
    "\n",
    "# This is how we can supply external pre-generated matrices\n",
    "# Covariance[\"PbPb5020\"][(\"R_AA\", \"C0\")][(\"R_AA\", \"C0\")] = RawCov55E[\"Matrix\"]\n",
    "# Covariance[\"PbPb5020\"][(\"R_AA\", \"C1\")][(\"R_AA\", \"C1\")] = RawCov66E[\"Matrix\"]\n",
    "\n",
    "\n",
    "# Assign data to the dictionary\n",
    "AllData[\"design\"] = RawDesign[\"Design\"]\n",
    "AllData[\"model\"] = Prediction\n",
    "AllData[\"data\"] = Data\n",
    "AllData[\"cov\"] = Covariance\n",
    "\n",
    "# Save to the desired pickle file\n",
    "with open('input/default.p', 'wb') as handle:\n",
    "    pickle.dump(AllData, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1-a: plot data\n",
    "\n",
    "The measured data are stored under the `data` key in AllData.  Take a look at the print statement output to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AllData['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(figsize = (5, 5), ncols = 1, nrows = 1)\n",
    "\n",
    "DataX    = ______\n",
    "DataY    = ______\n",
    "DataStat = ______\n",
    "DataSys  = ______\n",
    "DataErr  = np.sqrt(DataStat**2 + DataSys**2)\n",
    "\n",
    "axes.errorbar(DataX, DataY, yerr = DataErr, fmt='ro', label=\"Measurements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1-b: plot \"theory\" predictions on top of the data\n",
    "\n",
    "The theory predictions are stored under the `model` key in AllData.  Take a look at the print statement output to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AllData[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just repeating the defintion from above.\n",
    "DataX    = ______\n",
    "DataY    = ______\n",
    "DataStat = ______\n",
    "DataSys  = ______\n",
    "DataErr  = np.sqrt(DataStat**2 + DataSys**2)\n",
    "\n",
    "PredictionsY = ______\n",
    "PredictionsX = ______\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (5, 5), ncols = 1, nrows = 1)\n",
    "\n",
    "axes.errorbar(DataX, DataY, yerr = DataErr, fmt='ro', label=\"Measurements\")\n",
    "for Item in PredictionsY:\n",
    "    axes.plot(PredictionsX, Item, 'b-', alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1-c: plot the design points\n",
    "\n",
    "The deisgn points are stored under the `design` key in AllData. Take a look at the print statement output to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AllData['design'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(figsize = (15, 5), ncols = 3, nrows = 1)\n",
    "\n",
    "# Plot A vs B\n",
    "axes[0].set_xlabel('A')\n",
    "axes[0].set_ylabel('B')\n",
    "axes[0].scatter(______, ______)\n",
    "# Plot A vs C\n",
    "axes[1].set_xlabel('A')\n",
    "axes[1].set_ylabel('C')\n",
    "axes[1].scatter(______, ______)\n",
    "# Plot B vs C\n",
    "axes[2].set_xlabel('B')\n",
    "axes[2].set_ylabel('C')\n",
    "axes[2].scatter(______, ______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1-d: plot covariance matrix\n",
    "\n",
    "The covariance matrix between the measured data is stored under the `cov` key in AllData. Take a look at the print statement output to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AllData['cov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(figsize = (5, 5), ncols = 1, nrows = 1)\n",
    "\n",
    "Covariance = ______\n",
    "\n",
    "axes.set_xlabel('Bin index')\n",
    "axes.set_ylabel('Bin index')\n",
    "axes.imshow(Covariance, cmap = 'Blues', interpolation = 'nearest', extent=[0,6,6,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: clean past files\n",
    "\n",
    "Results are cached automatically so that we can avoid repeating expensive calculations when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean past MCMC samples\n",
    "if os.path.exists('cache/mcmc_chain.hdf'):\n",
    "    os.remove(\"cache/mcmc_chain.hdf\")\n",
    "\n",
    "# Clean past emulator\n",
    "for system in AllData[\"systems\"]:\n",
    "    if os.path.exists('cache/emulator/' + system + \".pkl\"):\n",
    "        os.remove('cache/emulator/' + system + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: run emulator\n",
    "\n",
    "Now that we've setup our data, we can setup the Gaussian Process Emulator. It will automatically load our data and train according to the settings specified in this section.\n",
    "\n",
    "After training, we access the emulator predictions via the `EmulatorPbPb5020` object defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 -m src.emulator --retrain --npc 3 --nrestarts 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import lazydict, emulator\n",
    "EmulatorPbPb5020 = emulator.Emulator.from_cache('PbPb5020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: plot emulator prediction for some random point, compare to \"truth\"\n",
    "\n",
    "We can check the performance of the emulator by asking it to predict a random point, and the comparing it to the truth. Remeber that our \"truth\" is generated according to:\n",
    "\n",
    "$$y = A + B\\frac{x}{100} + C(\\frac{x}{100})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomPoint = [0.1, 0.6, 0.8]\n",
    "\n",
    "# NOTE: Since we ask for a single point, the prediction array has shape (1, 6)\n",
    "Prediction = {\"PbPb5020\": EmulatorPbPb5020.predict([RandomPoint])}\n",
    "\n",
    "print(Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(figsize = (5, 5), ncols = 1, nrows = 1)\n",
    "\n",
    "TruthX = np.array(range(100))\n",
    "TruthY = ______\n",
    "\n",
    "DataX     = ______\n",
    "Predicted = ______\n",
    "\n",
    "axes.set_xlabel('X')\n",
    "axes.set_ylabel('Y')\n",
    "axes.plot(TruthX, TruthY, 'r-')\n",
    "axes.plot(DataX, Predicted, 'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: MCMC sampling\n",
    "\n",
    "We now use MCMC to calculate the posterior, utilizing the GPE and the experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('cache/mcmc_chain.hdf'):\n",
    "    os.remove(\"cache/mcmc_chain.hdf\")\n",
    "! python3 -m src.mcmc --nwalkers 100 --nburnsteps 1000 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "src.Initialize()\n",
    "from src import mcmc\n",
    "chain = mcmc.Chain()\n",
    "MCMCSamples = chain.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3-a: plot posterior function directly for A = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 0.3\n",
    "Grid = [[A, B * 0.01, C * 0.01] for B in range(10, 100, 10) for C in range(10, 100, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Posterior = ______\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (5, 5), ncols = 1, nrows = 1)\n",
    "\n",
    "axes.set_xlabel('B')\n",
    "axes.set_ylabel('C')\n",
    "axes.imshow(Posterior.reshape(9, 9), cmap = 'Blues', extent = [0.05,0.95,0.95,0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3-b: plot \"chi^2\" from data and \"truth\", again for A = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataX    = ______\n",
    "DataY    = ______\n",
    "DataStat = ______\n",
    "DataSys  = ______\n",
    "DataErr  = np.sqrt(DataStat**2 + DataSys**2)\n",
    "\n",
    "Chi2 = np.zeros(len(Grid))\n",
    "for i, p in enumerate(Grid):\n",
    "    TruthY = [______ for x in DataX]\n",
    "    Chi2[i] = ______\n",
    "    \n",
    "figure, axes = plt.subplots(figsize = (5, 5), ncols = 1, nrows = 1)\n",
    "\n",
    "axes.set_xlabel('B')\n",
    "axes.set_ylabel('C')\n",
    "axes.imshow(Chi2.reshape(9, 9), cmap = 'Greens', extent = [0.05,0.95,0.95,0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: analyze the posterior samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC samples plot\n",
    "\n",
    "Plot the parameters explored by each walker of the MCMC. They should cover the parameter values of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with chain.dataset() as d:\n",
    "    W = d.shape[0]     # number of walkers\n",
    "    S = d.shape[1]     # number of steps\n",
    "    N = d.shape[2]     # number of paramters\n",
    "    T = int(S / 200)   # \"thinning\"\n",
    "    A = 20 / W\n",
    "    figure, axes = plt.subplots(figsize = (15, 2 * N), ncols = 1, nrows = N)\n",
    "    for i, ax in enumerate(axes):\n",
    "        for j in range(0, W):\n",
    "            ax.plot(range(0, S, T), d[j, ::T, i], alpha = A)\n",
    "    plt.tight_layout(True)\n",
    "    plt.savefig('plots/MCMCSamples.pdf', dpi = 192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior on parameters\n",
    "\n",
    "Shows the probability distribution for parameters according to the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDimension = len(AllData[\"labels\"])\n",
    "Ranges = np.array(AllData[\"ranges\"]).T\n",
    "figure, axes = plt.subplots(figsize = (3 * NDimension, 3 * NDimension), ncols = NDimension, nrows = NDimension)\n",
    "Names = AllData[\"labels\"]\n",
    "for i, row in enumerate(axes):\n",
    "    for j, ax in enumerate(row):\n",
    "        if i==j:\n",
    "            ax.hist(MCMCSamples[:,i], bins=50,\n",
    "                    range=Ranges[:,i], histtype='step', color='green')\n",
    "            ax.set_xlabel(Names[i])\n",
    "            ax.set_xlim(*Ranges[:,j])\n",
    "        if i>j:\n",
    "            ax.hist2d(MCMCSamples[:, j], MCMCSamples[:, i], \n",
    "                      bins=50, range=[Ranges[:,j], Ranges[:,i]], \n",
    "                      cmap='Greens')\n",
    "            ax.set_xlabel(Names[j])\n",
    "            ax.set_ylabel(Names[i])\n",
    "            ax.set_xlim(*Ranges[:,j])\n",
    "            ax.set_ylim(*Ranges[:,i])\n",
    "        if i<j:\n",
    "            ax.axis('off')\n",
    "plt.tight_layout(True)\n",
    "plt.savefig('plots/Correlation.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior on top of data\n",
    "\n",
    "Compare the parameters determined according to the posterior to the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Examples = MCMCSamples[ np.random.choice(range(len(MCMCSamples)), 5000), :]\n",
    "\n",
    "TempPrediction = {\"PbPb5020\": EmulatorPbPb5020.predict(Examples)}\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (5, 5), ncols = 1, nrows = 1)\n",
    "\n",
    "axes.set_xlabel(r\"$X$\")\n",
    "axes.set_ylabel(r\"$Y$\")\n",
    "DataX    = AllData[\"data\"]['PbPb5020']['Y']['C0']['x']\n",
    "DataY    = AllData[\"data\"]['PbPb5020']['Y']['C0']['y']\n",
    "DataStat = AllData[\"data\"]['PbPb5020']['Y']['C0']['yerr']['stat'][:,0]\n",
    "DataSys  = AllData[\"data\"]['PbPb5020']['Y']['C0']['yerr']['sys'][:,0]\n",
    "DataErr  = np.sqrt(DataStat**2 + DataSys**2)\n",
    "\n",
    "for i, y in enumerate(TempPrediction['PbPb5020']['Y']['C0']):\n",
    "    axes.plot(DataX, y, 'b-', alpha=0.0025, label=\"Posterior\" if i==0 else '')\n",
    "axes.errorbar(DataX, DataY, yerr = DataErr, fmt='ro', label=\"Measurements\")\n",
    "\n",
    "plt.tight_layout(True)\n",
    "figure.savefig('plots/ObservablePosterior.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close all plots to save memory\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
