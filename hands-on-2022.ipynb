{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on exercise with the JETSCAPE STAT package\n",
    "\n",
    "Based on materials from Yi Chen - thanks!\n",
    "\n",
    "We want to gain practical experience with the JETSCAPE STAT Bayesian analysis package.\n",
    "In order to focus on the package rather than the physics, we'll investigate a simple toy model for the dijet asymmetry, $A_{\\text{J}}$.\n",
    "$A_{\\text{J}}$ is defined as the difference between the two jets divided by the sum <a name=\"footnote-1\"></a>[<sup>[1]</sup>](#footnote-1).\n",
    "Specifically,\n",
    "\n",
    "$$A_{\\mathrm{J}} = \\frac{p_{\\mathrm{T, 1}} - p_{\\mathrm{T, 2}}}{p_{\\mathrm{T, 1}} + p_{\\mathrm{T, 2}}}$$\n",
    "\n",
    "Such an asymmetry is already apparent at the level of the event display\n",
    "\n",
    "<center><img src=\"img/atlas_dijet_event_display.png\" width=70% /></center>\n",
    "\n",
    "Measured as $A_{\\text{J}}$ in [Phys. Rev. Lett. 105 (2010) 252303](https://inspirehep.net/record/878733), with the PbPb data in black circles, pp in white circles, and HIJING in yellow\n",
    "\n",
    "<center><img src=\"img/atlas_dijet_asymmetry_data.png\" width=70% /></center>\n",
    "\n",
    "<a name=\"footnote-1\"></a>1. [^](#cite_ref-1) : (For experimental reasons related to removing background and detector effects with unfolding, $A_{\\text{J}}$ has become somewhat less popular compared to $x_{\\text{J}} = p_{\\text{T, 2}}/p_{\\text{T, 1}}$. However, it's convenient for thinking about conceptually, so we'll use it here.)\n",
    "\n",
    "### Energy loss toy model\n",
    "\n",
    "For today's exercise, We will construct a model to describe the energy loss observed in the dijet asymmetry.  For this model, we consider back-to-back dijets.  Each jet can lose energy, and the lost energy is parameterized as\n",
    "\n",
    "$$ \\Delta p_{\\mathrm{T}} / p_{\\mathrm{T}} \\sim A \\times Gaus(1, 1)$$\n",
    "\n",
    "In addition to the energy loss contribution, we have extra \"apparent\" smearing directly applied to the $A_J$. This contribution comes from the fact that we have other processes going on in the events (three jets etc).  It is parameterized as a Gaussian smearing on $A_J$ with width $B$, centered at 0 (ie. for approximately balanced dijets). So there are two total parameters: $A$ and $B$.\n",
    "\n",
    "For our toy, will we consider the measurement to be done in two bins of centrality.  One in central events, where ($A$, $B$) are both relevant, and another one in very peripheral events, where only the parameter ($B$) is relevant. To summarize:\n",
    "\n",
    "|           | Central | Peripheral |\n",
    "| --------- | ------- | ---------- |\n",
    "| Quenching | Jets lose energy by $\\Delta p_{\\text{T}} / p_{\\text{T}} \\sim A \\times \\text{Gaus}(1, 1)$ | N/A |\n",
    "| Smearing  | Smeared by $\\text{Gaus}(0, B)$ | Smeared by $\\text{Gaus}(0, B)$ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Basic setup, loading python packages\n",
    "\n",
    "Note that much (but not all!) of the code is parametrized, so it can be adapted to other datasets fairly easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import src.reader as Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Input files\n",
    "\n",
    "Performing a full scale Bayesian analysis often requires a good deal of organization.\n",
    "Even if experimental measurements are on HEPdata, they are usually not formatted in a standard manner.\n",
    "Files with design points and predictions may be in many different formats, making collaboration more difficult.\n",
    "\n",
    "One of the benefit of the STAT package is the standardized input file formats. The full file specification is describe [here](https://www.evernote.com/l/ACWFCWrEcPxHPJ3_P0zUT74nuasCoL_DBmY). We will explore the different formats below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for exploring input files\n",
    "\n",
    "from typing import List, Sequence\n",
    "\n",
    "def read_file_with_slices(filename: Path) -> List[str]:\n",
    "    \"\"\"Read file into list, allowing us to focus on particular slices.\n",
    "    \"\"\"\n",
    "    with open(filename) as f:\n",
    "        return [l for l in f]\n",
    "\n",
    "def print_sequence_helper(seq: Sequence[str]) -> None:\n",
    "    print(\"\".join(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some base paths for convenience\n",
    "base_path = Path(\"input/AJExample\")\n",
    "img_base_path = Path(\"plots\")\n",
    "img_base_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data files\n",
    "\n",
    "Data files contain the measurements from experiments in a standardized yet flexible format.\n",
    "Usually, you will acquire these files from HEPdata or directly from an experiment.\n",
    "In the case of our toy model, we provide the files directly (since we've generating them according to a toy)\n",
    "\n",
    "Each file contains general header info, specifies the columns, and the data itself. For the example, I show only the central values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data_file = read_file_with_slices(base_path / \"Data_Selection1.dat\")\n",
    "# First, take a glance at the file\n",
    "print_sequence_helper(example_data_file[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General header info, covering where it came from (experiment, collision system, centrality, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sequence_helper(example_data_file[0:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Header specification of the columns. Here, we have the x bin edges, the central value, the lower and upper statistical error, and the lower and upper systematic error. This can also include additional classes of uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sequence_helper(example_data_file[7:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the data itself. We'll just take a look at a quick subset for brevity (repeating the column header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sequence_helper(example_data_file[7:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design points\n",
    "\n",
    "Documents the parameter values that are used for running the model. Can distribute them in many different ways, including taking advantage of machine learning techniques such as active learning to attempt to optimize calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_design_points_file = read_file_with_slices(base_path / \"Design.dat\")\n",
    "# First, take a glance at the file\n",
    "print_sequence_helper(example_design_points_file[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Header info, specifying the relevant parameters. Note that you need to keep track of your generation range (this could be included in the header. Here we specify the minimum, but adding more doesn't hurt). However many you generate depends on many factors, including the parameterizaton. At least 10 / parameter is a reasonable start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sequence_helper(example_design_points_file[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The design points themselves. One row per set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sequence_helper(example_design_points_file[2:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction files\n",
    "\n",
    "These files contain the predictions run at the design points specified in the previous file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_predictions_file = read_file_with_slices(base_path / \"Prediction_Selection1.dat\")\n",
    "# First, take a glance at the file\n",
    "print_sequence_helper(example_predictions_file[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Header information includes the specification, the corresponding data file, and the design points used to generate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sequence_helper(example_predictions_file[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions themselves.  Each row is a prediction for **one data point from all design points**. Here, we generated 40 design points, so there are 40 values in each row. The rows match up with the binning in the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sequence_helper(example_predictions_file[3:4])\n",
    "print(f\"Number of design points: {len(example_predictions_file[3:4][0].split(' '))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, design points, and predictions from text files\n",
    "\n",
    "The `Reader` class implements the interface between input data files and the code.  There are functions to read in experimental data, externally-supplied covariance matrix, design points, and calculations for the design points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data files\n",
    "RawData1 = Reader.ReadData(base_path / \"Data_Selection1.dat\")   # Central bin data\n",
    "RawData2 = Reader.ReadData(base_path / \"Data_Selection2.dat\")   # Peripheral bin data\n",
    "\n",
    "# Read covariance -- if you have covariance matrix from the experiments for example\n",
    "# We will estimate the covariance separately below\n",
    "# RawCov1 = Reader.ReadCovariance('input/AJExample/Covariance_Selection1_TypeX.dat')\n",
    "# RawCov2 = Reader.ReadCovariance('input/AJExample/Covariance_Selection2_TypeX.dat')\n",
    "\n",
    "# Read design points\n",
    "RawDesign = Reader.ReadDesign(base_path / \"Design.dat\")   # Design points!\n",
    "\n",
    "# Read model prediction\n",
    "# Here, these are our toy calculations\n",
    "RawPrediction1 = Reader.ReadPrediction(base_path / \"Prediction_Selection1.dat\")   # Calculation for central bin\n",
    "RawPrediction2 = Reader.ReadPrediction(base_path / \"Prediction_Selection2.dat\")   # Calculation for peripheral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stores everything into an expected dictionary format, which is easily convertable and consumable by the STAT package\n",
    "\n",
    "In addition to reading inputs, there is also a `EstimateCovariance` function that estimates the covariance for you.  It is configurable to do different correlation treatment for different systematic uncertainty sources (and then add them all up!).  We can also correlate across different measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup analysis\n",
    "\n",
    "We've read the inputs, but we still need to compile all of the inputs into a format that can be understood by the STAT package.\n",
    "This problem is fairly flexible, so it's not always straightforwad to automate.\n",
    "By configuring by hand, we can be confident that we're working with the correct inputs\n",
    "\n",
    "First, we begin with the basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionary\n",
    "# The package expects all inputs to be in a properly formatted dictionary.\n",
    "# This dict is maintained as ~a global object\n",
    "AllData = {}\n",
    "\n",
    "# We have two different centrality bins, so we need to tell the package about them.\n",
    "C0 = 'Central'\n",
    "C1 = 'Peripheral'\n",
    "\n",
    "# Basic information\n",
    "AllData[\"systems\"] = [\"PbPb5020\"]                 # List of collision systems we are doing\n",
    "AllData[\"keys\"] = RawDesign[\"Parameter\"]          # Get the \"A\" and \"B\" from the design file\n",
    "AllData[\"labels\"] = RawDesign[\"Parameter\"]        # Get the \"A\" and \"B\" from the design file\n",
    "AllData[\"ranges\"] = [(0, 0.3), (0, 0.3)]          # Range of A and B. You need this information externally,\n",
    "                                                  # or to store it in the design points header.\n",
    "AllData[\"observables\"] = [('A_J', [C0, C1])]      # We measure A_J with two bins: \"Central\" and \"Peripheral\"\n",
    "# In this example \"C0\" is central data, and \"C1\" is peripheral => see above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the basic structure configured, we can now start packaging up our input into the matching format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data points\n",
    "Data = {\"PbPb5020\": {\"A_J\": {C0: RawData1[\"Data\"], C1: RawData2[\"Data\"]}}}\n",
    "\n",
    "# Model predictions\n",
    "# We provide the binning from the experimental data. It's critical that this matches!\n",
    "Prediction = {\"PbPb5020\": {\"A_J\": {C0: {\"Y\": RawPrediction1[\"Prediction\"], \"x\": RawData1[\"Data\"]['x']},\n",
    "                                   C1: {\"Y\": RawPrediction2[\"Prediction\"], \"x\": RawData2[\"Data\"]['x']}}}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can estimate the correlations among uncertainties, as decribed by Yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation length options\n",
    "# Change to 9999 to make it fully correlated,or -1 for fully uncorrelated\n",
    "# Also try 0.1 for partially correlated\n",
    "CorrelationLength = -1\n",
    "OffDiagonalCorrelationLength = -1\n",
    "\n",
    "# Covariance matrices - the indices are [system][measurement1][measurement2], each one is a block of matrix\n",
    "Covariance = Reader.InitializeCovariance(Data)\n",
    "Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C0)] = \\\n",
    "    Reader.EstimateCovariance(RawData1, RawData1, SysLength = {\"default\": CorrelationLength}, ScaleX = False)\n",
    "Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C1)] = \\\n",
    "    Reader.EstimateCovariance(RawData2, RawData2, SysLength = {\"default\": CorrelationLength}, ScaleX = False)\n",
    "Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C1)] = \\\n",
    "    Reader.EstimateCovariance(RawData1, RawData2, SysLength = {\"default\": OffDiagonalCorrelationLength}, ScaleX = False)\n",
    "Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C0)] = \\\n",
    "    Reader.EstimateCovariance(RawData2, RawData1, SysLength = {\"default\": OffDiagonalCorrelationLength}, ScaleX = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all of that preparation, store everying in the global dict. The package expects this to be stored in `input/default.p`, so take care if working on multiple projects at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign data to the dictionary\n",
    "AllData[\"design\"] = RawDesign[\"Design\"]\n",
    "AllData[\"model\"] = Prediction\n",
    "AllData[\"data\"] = Data\n",
    "AllData[\"cov\"] = Covariance\n",
    "\n",
    "# Save to the desired file\n",
    "with open('input/default.p', 'wb') as handle:\n",
    "    pickle.dump(AllData, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore our input files\n",
    "\n",
    "Let's take a look at what we're working with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's take a look at the input data!\n",
    "\n",
    "# Setup\n",
    "system_count = len(AllData[\"systems\"])\n",
    "figure, axes = plt.subplots(figsize = (15, 5 * system_count), ncols = 2, nrows = 1)\n",
    "\n",
    "# We only have one observable, the AJ, so we always take the first entry\n",
    "# If there were more, we would have to iterate over this index too (and likely adjust the sub_observable_index)\n",
    "observable_index = 0\n",
    "\n",
    "for sub_observable_index, ax in enumerate(axes):\n",
    "    ax.set_xlabel(r\"$A_{J}$\")\n",
    "    ax.set_ylabel(r\"$dN/dA_{J}$\")\n",
    "\n",
    "    # Extract some information\n",
    "    system_name = AllData[\"systems\"][0]\n",
    "    # Name (key) of the first observable.\n",
    "    observable_name = AllData[\"observables\"][observable_index][0]\n",
    "    # The second entry in the tuple is a list of the observable names\n",
    "    centrality = AllData[\"observables\"][observable_index][1][sub_observable_index]\n",
    "\n",
    "    # Actual bins and data points\n",
    "    DX = AllData[\"data\"][system_name][observable_name][centrality]['x']\n",
    "    DY = AllData[\"data\"][system_name][observable_name][centrality]['y']\n",
    "    # Combine the statistical and systematic errors in quadrature\n",
    "    DE = np.sqrt(\n",
    "        AllData[\"data\"][system_name][observable_name][centrality]['yerr']['stat'][:,0]**2\n",
    "        + AllData[\"data\"][system_name][observable_name][centrality]['yerr']['sys'][:,0]**2\n",
    "    )\n",
    "                \n",
    "    ax.errorbar(DX, DY, yerr = DE, fmt='ro', label=\"Measurements\")\n",
    "\n",
    "axes[0].set_title('Central')\n",
    "axes[1].set_title('Peripheral')\n",
    "\n",
    "plt.tight_layout()\n",
    "figure.savefig(img_base_path / 'InputData.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can look at the design points. We want to aim to cover our parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2D scatter plot of the design points\n",
    "figure, axis = plt.subplots(figsize = (5, 5), ncols = 1, nrows = 1)\n",
    "axis.plot(AllData[\"design\"][:,0], AllData[\"design\"][:,1], 'o')\n",
    "axis.set_xlabel('A')\n",
    "axis.set_ylabel('B')\n",
    "figure.savefig(img_base_path / 'DesignPoints.pdf', dpi = 192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can compare the calculations to the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the model predictions for convenience\n",
    "_model_predictions = AllData[\"model\"]\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (15, 5 * system_count), ncols = 2, nrows = 1)\n",
    "\n",
    "# We only have one observable, the AJ, so we always take the first entry\n",
    "# If there were more, we would have to iterate over this index too (and likely adjust the sub_observable_index)\n",
    "observable_index = 0\n",
    "\n",
    "for sub_observable_index, ax in enumerate(axes):\n",
    "    ax.set_xlabel(r\"$A_{J}$\")\n",
    "    ax.set_ylabel(r\"$dN/dA_{J}$\")\n",
    "\n",
    "    # Extract some information\n",
    "    system_name = AllData[\"systems\"][0]\n",
    "    # Name (key) of the first observable.\n",
    "    observable_name = AllData[\"observables\"][observable_index][0]\n",
    "    # The second entry in the tuple is a list of the observable names\n",
    "    centrality = AllData[\"observables\"][observable_index][1][sub_observable_index]\n",
    "\n",
    "    # Actual bins and data points\n",
    "    DX = AllData[\"data\"][system_name][observable_name][centrality]['x']\n",
    "    DY = AllData[\"data\"][system_name][observable_name][centrality]['y']\n",
    "    # Combine the statistical and systematic errors in quadrature\n",
    "    DE = np.sqrt(\n",
    "        AllData[\"data\"][system_name][observable_name][centrality]['yerr']['stat'][:,0]**2\n",
    "        + AllData[\"data\"][system_name][observable_name][centrality]['yerr']['sys'][:,0]**2\n",
    "    )\n",
    "                \n",
    "    for i, y in enumerate(_model_predictions[system_name][observable_name][centrality]['Y']):\n",
    "        ax.plot(DX, y, 'b-', alpha=0.1, label=\"Posterior\" if i==0 else '')\n",
    "    ax.errorbar(DX, DY, yerr = DE, fmt='ro', label=\"Measurements\")\n",
    "\n",
    "axes[0].set_title('Central')\n",
    "axes[1].set_title('Peripheral')\n",
    "    \n",
    "plt.tight_layout()\n",
    "figure.savefig(img_base_path / 'Design.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the covariance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the maximum value from the different covariances so that we can put all plots on the same scale\n",
    "MaxValue = np.array(\n",
    "    [Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C0)].max(),\n",
    "     Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C1)].max(),\n",
    "     Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C0)].max(),\n",
    "     Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C1)].max()]).max()\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (6, 6), ncols = 2, nrows = 2)\n",
    "axes[0][0].imshow(Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C0)], vmin=0, vmax=MaxValue)\n",
    "axes[0][1].imshow(Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C1)], vmin=0, vmax=MaxValue)\n",
    "axes[1][0].imshow(Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C0)], vmin=0, vmax=MaxValue)\n",
    "axes[1][1].imshow(Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C1)], vmin=0, vmax=MaxValue)\n",
    "\n",
    "axes[0][0].set_xlabel('Central')\n",
    "axes[0][1].set_xlabel('Central')\n",
    "axes[1][0].set_xlabel('Peripheral')\n",
    "axes[1][1].set_xlabel('Peripheral')\n",
    "\n",
    "axes[0][0].set_ylabel('Central')\n",
    "axes[0][1].set_ylabel('Peripheral')\n",
    "axes[1][0].set_ylabel('Central')\n",
    "axes[1][1].set_ylabel('Peripheral')\n",
    "\n",
    "figure.tight_layout()\n",
    "figure.savefig(img_base_path / 'Covariance.pdf', dpi = 192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These reflect the choices we made above in terms of estimate the covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean past files so that they don't haunt us later on\n",
    "\n",
    "This is relevant due to the global state of the package. Don't worry too much about the details here. Just run it and keep in mind that this is a good thing to check if you run into an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean past MCMC samples\n",
    "mcmc_samples_cache = Path('cache/mcmc_chain.hdf')\n",
    "if mcmc_samples_cache.exists():\n",
    "    mcmc_samples_cache.unlink()\n",
    "\n",
    "# Clean past emulator\n",
    "for system in AllData[\"systems\"]:\n",
    "    emulator_cache = Path(\"cache/emulator\") / f\"{system}.pkl\"\n",
    "    if emulator_cache.exists():\n",
    "        emulator_cache.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train the GP emulator\n",
    "\n",
    "We want to train the Gaussian Process emulator to cover the prediction the entire phase space.\n",
    "It will take the inputs that we've stored in the global dict, and train the emulator, utilzing some set number of principal components.\n",
    "Here, we've found 8 to be sufficient to describe 99.5% of the variance, but you could tune this further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the emulator options\n",
    "! python3 -m src.emulator --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train emulator with 8 principle components\n",
    "# (it implicitly knowns to run on PbPb5020)\n",
    "! python3 -m src.emulator --retrain --npc 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now trained the emulator, and the results were only written to file (`cache/emulator/PbPb5020.pkl`).\n",
    "As the filename implies, we often train a different emulator for each $\\sqrt{s}$.\n",
    "Since we want to work with the emulator directly for plotting purposes, we'll load it now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in emulator object into this notebook for plotting purposes\n",
    "from src import emulator\n",
    "EmulatorPbPb5020 = emulator.Emulator.from_cache('PbPb5020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can experiment with the emulator.\n",
    "Let's try out a few predictions to see if they make sense.\n",
    "eg. [0.0, 0.25], [0.1, 0.0], [0.2, 0.1], etc\n",
    "\n",
    "Note the maximum range is 0.3.  What will happen if you put something larger than 0.3?  For example [0.1, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "_prediction = {\"PbPb5020\": EmulatorPbPb5020.predict([[0.0, 0.25]])}\n",
    "system_count = len(AllData[\"systems\"])\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (15, 5 * system_count), ncols = 2, nrows = 1)\n",
    "\n",
    "# We only have one observable, the AJ, so we always take the first entry\n",
    "# If there were more, we would have to iterate over this index too (and likely adjust the sub_observable_index)\n",
    "observable_index = 0\n",
    "\n",
    "for sub_observable_index, ax in enumerate(axes):\n",
    "    ax.set_xlabel(r\"$A_{J}$\")\n",
    "    ax.set_ylabel(r\"$dN/dA_{J}$\")\n",
    "\n",
    "    # Extract some information\n",
    "    system_name = AllData[\"systems\"][0]\n",
    "    # Name (key) of the first observable.\n",
    "    observable_name = AllData[\"observables\"][observable_index][0]\n",
    "    # The second entry in the tuple is a list of the observable names\n",
    "    centrality = AllData[\"observables\"][observable_index][1][sub_observable_index]\n",
    "\n",
    "    # Actual bins and data points\n",
    "    DX = AllData[\"data\"][system_name][observable_name][centrality]['x']\n",
    "    DY = AllData[\"data\"][system_name][observable_name][centrality]['y']\n",
    "    # Combine the statistical and systematic errors in quadrature\n",
    "    DE = np.sqrt(\n",
    "        AllData[\"data\"][system_name][observable_name][centrality]['yerr']['stat'][:,0]**2\n",
    "        + AllData[\"data\"][system_name][observable_name][centrality]['yerr']['sys'][:,0]**2\n",
    "    )\n",
    "                \n",
    "    ax.plot(DX, _prediction[system_name][observable_name][centrality][0], 'b-', alpha=1, label=\"Posterior\")\n",
    "    ax.errorbar(DX, DY, yerr = DE, fmt='ro', label=\"Measurements\")\n",
    "\n",
    "axes[0].set_title('Central')\n",
    "axes[1].set_title('Peripheral')\n",
    "\n",
    "axes[1].legend(frameon=False, fontsize=16, loc=\"upper right\")\n",
    "figure.tight_layout()\n",
    "figure.savefig(img_base_path / 'PredictionTest.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: MCMC sampling\n",
    "\n",
    "Using the emulator, we can sample the posterior with MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 -m src.mcmc --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will run 100 walkers (chains), with 200 burn in steps. We'll then run 200 steps further.\n",
    "For a real analysis, you'll need much more than this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make sure that our cache is clean before we try to sample\n",
    "if mcmc_samples_cache.exists():\n",
    "    mcmc_samples_cache.unlink()\n",
    "! python3 -m src.mcmc --nwalkers 100 --nburnsteps 200 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much like the emulator, the MCMC writes the chain to file.\n",
    "To work with it, we need to explicitly load the posterior samples into the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now important the main package. This is important, because it gives us direct access to the global state\n",
    "import src\n",
    "src.Initialize()\n",
    "from src import mcmc\n",
    "chain = mcmc.Chain()\n",
    "MCMCSamples = chain.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Explore the MCMC and the posterior\n",
    "\n",
    "Assuming all of the above worked, we're now at the point where we can evaluate the MCMC performance, our most probable paramteers, as well as how well our posterior describes our data.\n",
    "\n",
    "To start, let's take a quick look at the MCMC performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walker vs step\n",
    "names = AllData[\"labels\"]\n",
    "\n",
    "with chain.dataset() as d:\n",
    "    W = d.shape[0]     # number of walkers\n",
    "    S = d.shape[1]     # number of steps\n",
    "    N = d.shape[2]     # number of parameters\n",
    "    T = int(S / 100)   # \"thinning\" -> plot only a subset of the walkers to keep the plot interpretable\n",
    "    # Adjsut the alpha based on how many walks we will look at\n",
    "    img_alpha = 20 / W\n",
    "    figure, axes = plt.subplots(figsize = (15, 2 * N), ncols = 1, nrows = N)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.set_ylabel(names[i])\n",
    "        ax.set_xlabel('Step')\n",
    "        for j in range(0, W):\n",
    "            ax.plot(range(0, S, T), d[j, ::T, i], alpha = img_alpha)\n",
    "    figure.tight_layout()\n",
    "    plt.savefig(img_base_path / 'MCMCSamples.pdf', dpi = 192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can take a look at the extracted parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDimension = len(AllData[\"labels\"])\n",
    "Ranges = np.array(AllData[\"ranges\"]).T\n",
    "figure, axes = plt.subplots(figsize = (3 * NDimension, 3 * NDimension), ncols = NDimension, nrows = NDimension)\n",
    "Names = AllData[\"labels\"]\n",
    "for i, row in enumerate(axes):\n",
    "    for j, ax in enumerate(row):\n",
    "        if i==j:\n",
    "            ax.hist(MCMCSamples[:,i], bins=50,\n",
    "                    range=Ranges[:,i], histtype='step', color='green')\n",
    "            ax.set_xlabel(Names[i])\n",
    "            ax.set_xlim(*Ranges[:,j])\n",
    "        if i>j:\n",
    "            ax.hist2d(MCMCSamples[:, j], MCMCSamples[:, i], \n",
    "                      bins=50, range=[Ranges[:,j], Ranges[:,i]], \n",
    "                      cmap='Greens')\n",
    "            ax.set_xlabel(Names[j])\n",
    "            ax.set_ylabel(Names[i])\n",
    "            ax.set_xlim(*Ranges[:,j])\n",
    "            ax.set_ylim(*Ranges[:,i])\n",
    "        if i<j:\n",
    "            ax.axis('off')\n",
    "figure.tight_layout()\n",
    "plt.savefig(img_base_path / 'Correlation.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior is quite well constrained for our simple toy model!\n",
    "\n",
    "However, this isn't enough. How does the posterior describe the data?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab some of the MCMC samples. This is sampling the posterior\n",
    "_examples = MCMCSamples[ np.random.choice(range(len(MCMCSamples)), 2000), :]\n",
    "_prediction = {\"PbPb5020\": EmulatorPbPb5020.predict(_examples)}\n",
    "_system_count = len(AllData[\"systems\"])\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (15, 5 * _system_count), ncols = 2, nrows = 1)\n",
    "\n",
    "# We only have one observable, the AJ, so we always take the first entry\n",
    "# If there were more, we would have to iterate over this index too (and likely adjust the sub_observable_index)\n",
    "observable_index = 0\n",
    "\n",
    "for sub_observable_index, ax in enumerate(axes):\n",
    "    ax.set_xlabel(r\"$A_{J}$\")\n",
    "    ax.set_ylabel(r\"$dN/dA_{J}$\")\n",
    "\n",
    "    # Extract some information\n",
    "    system_name = AllData[\"systems\"][0]\n",
    "    # Name (key) of the first observable.\n",
    "    observable_name = AllData[\"observables\"][observable_index][0]\n",
    "    # The second entry in the tuple is a list of the observable names\n",
    "    centrality = AllData[\"observables\"][observable_index][1][sub_observable_index]\n",
    "\n",
    "    # Actual bins and data points\n",
    "    DX = AllData[\"data\"][system_name][observable_name][centrality]['x']\n",
    "    DY = AllData[\"data\"][system_name][observable_name][centrality]['y']\n",
    "    # Combine the statistical and systematic errors in quadrature\n",
    "    DE = np.sqrt(\n",
    "        AllData[\"data\"][system_name][observable_name][centrality]['yerr']['stat'][:,0]**2\n",
    "        + AllData[\"data\"][system_name][observable_name][centrality]['yerr']['sys'][:,0]**2\n",
    "    )\n",
    "                \n",
    "    for i, y in enumerate(_prediction[system_name][observable_name][centrality]):\n",
    "        ax.plot(DX, y, 'b-', alpha=0.005, label=\"Posterior\" if i==0 else '')\n",
    "    ax.errorbar(DX, DY, yerr = DE, fmt='ro', label=\"Measurements\")\n",
    "\n",
    "axes[0].set_title('Central')\n",
    "axes[1].set_title('Peripheral')\n",
    "\n",
    "axes[1].legend(frameon=False, fontsize=16, loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "figure.savefig(img_base_path / 'ObservablePosterior.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our posterior describes our toy data quite well (as we would hope!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close all plots to save memory\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've made it!\n",
    "\n",
    "Let's take a look back at the correlations between the uncertainties. For example, what happens for if they're both highly correlated? This can be have a critical impact on your result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f4e297e232d26b20080ba42bd98ed16bbb2fe9e027a7d36907dd8167df238ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
